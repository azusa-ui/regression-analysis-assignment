---
title: "Group 1 : Multivariable Logistic Regression Analysis"
author:
  - "AHMAD ZULFAHMI BIN SHA'ARI (23202546)"
  - "MOHD FAIZ BIN MOHD GHAZALI (23202458)"
  - "MUHAMAD SYAFIQ BIN ZAINUL ABIDIN (23202675)"
  - "ZAINAL BIN ZULKIFLI  (23203043)"
date: today
format: 
  html:
    theme: cosmo
    toc: true
    toc-location: left
    toc-depth: 3
    number-sections: true
    embed-resources: true
    code-fold: true
    code-tools: true
    smooth-scroll: true
    df-print: kable
    tbl-cap-location: top
    fig-cap-location: bottom
execute:
  warning: false
  message: false
  echo: true
---

# **Part A: Introduction and data generation**

In public health epidemiology, understanding the factors associated with mental health outcomes is critical for designing effective interventions. The objective of this analysis was to evaluate the association between years of working, physical activity, and obesity status with the odds of depression, and to determine whether obesity modifies the effect of physical activity on depression.

Additionally, the analysis aimed to develop a well-fitted and predictive logistic regression model by identifying and addressing influential observations, assessing model goodness-of-fit and discrimination, and estimating adjusted odds ratios to inform public health–relevant, targeted prevention strategies for depression, particularly among high-risk groups.

The R syntax for datasets was generated using Generative AI (ChatGPT 5.2) to emulate realistic epidemiological structures.The resulting dataset was then saved in CSV file format for subsequent analysis.

-   Generate synthetic depression dataset (n=200)

-   Depression: binary ("depressed" / "not depressed")

-   Years of working: 0-40

-   Physical activity score: 0-10

-   Obesity factor (2 levels)

-   Interaction: phys_activity \* obesity

Details of the data generation summary and files related to analysis are available at <https://github.com/azusa-ui/regression-analysis-assignment.git>

```{r}
# ============================================================
# Generate synthetic depression dataset (n=200)
# - depression: binary ("depressed" / "not depressed")
# - years_working: 0-40
# - phys_activity: 0-10
# - obesity factor (2 levels)
# - Interaction: phys_activity * obesity
# ============================================================

library(dplyr)
library(tibble)

set.seed(3030)
n <- 200

# Generate predictors
data_sim <- tibble(
  years_working = round(runif(n, 0, 40), 1),
  phys_activity = round(runif(n, 0, 10), 1),
  obesity = sample(c("obese", "not obese"), n, replace = TRUE, prob = c(0.3, 0.7))
) %>%
  mutate(
    obese_bin = ifelse(obesity == "obese", 1, 0),
    years_working_c = years_working - mean(years_working),
    phys_activity_c = phys_activity - mean(phys_activity)
  )

# Coefficients tuned for significance and realistic ORs
b0 <- -2.0        # intercept (~25% prevalence)
b1 <- 0.08        # years_working  
b2 <- -0.2       # PA main effect  
b3 <- 0.2        # obesity main effect  
b4 <- -0.3       # PA × obesity interaction  

# Generate outcome probabilities with clamping
data_sim <- data_sim %>%
  mutate(
    logit_p = b0 +
      b1 * years_working_c +
      b2 * phys_activity_c +
      b3 * obese_bin +
      b4 * phys_activity_c * obese_bin,
    prob_raw = plogis(logit_p),
    prob = pmin(pmax(prob_raw, 0.05), 0.95),  # clamp to avoid separation
    depression = if_else(runif(n) < prob, "depressed", "not depressed")
  ) %>%
  dplyr::select(depression, years_working, phys_activity, obesity)

# Save dataset
#write.csv(data_sim, "data_log2.csv", row.names = FALSE)

```

## Glimpse the generated dataset

```{r}
library(dplyr)
library(readr)

data <- read_csv("data_log2.csv")

# Round all numeric columns to integers
data <- data %>%
  mutate(across(where(is.numeric), ~ round(.x, 0)))

glimpse(data)

```

## Setting up the Environment

### Load Required Libraries

```{r}
# ================================
# Data Manipulation & Wrangling
# ================================
library(tidyverse)   # Data manipulation, tidyr, dplyr, purrr, ggplot2
library(modelr)      # Modeling helpers, predictions, resampling

# ================================
# Statistical Modeling & Diagnostics
# ================================
library(broom)           # Tidy model outputs
library(broom.helpers)   # Extended tidy helpers
library(performance)     # Model diagnostics (VIF, check_model)
library(car)             # Regression diagnostics (VIF, residuals)
library(lmtest)          # Likelihood ratio tests, model comparison
library(interactions)    # Interaction plots and simple slopes
library(pscl)            # Pseudo-R² (McFadden's)
library(ResourceSelection) # Hosmer-Lemeshow goodness-of-fit
library(QuantPsyc)       # Classification tables 
library(pROC)            # ROC curves and AUC
library(caret)           # Model evaluation, resampling

# ================================
# Regression Summary Tables
# ================================
library(gtsummary)   # Regression tables
library(gt)           # Formatted tables
library(knitr)        # Tables for R Markdown
library(kableExtra)   # Table formatting
library(DT)           # Interactive HTML tables


# ================================
# Data Exploration & Summarization
# ================================
library(summarytools) # Descriptive statistics, freq tables

# ================================
# Visualization
# ================================
library(ggplot2)      # Core plotting
library(GGally)       # Correlation plots, ggpairs
library(ggeffects)    # Predicted effects visualization
library(patchwork)    # Combine multiple ggplots
library(corrplot)     # Correlation matrix plots
library(viridis)


 
 
```

### Transform data

```{r}
# Change obesity and depression to factors and set reference levels
data <- data %>%
  mutate(
    obesity = factor(obesity, levels = c("not obese", "obese")),
    depression = factor(depression, levels = c("not depressed", "depressed"))
  )

library(labelled)
var_label(data$years_working) <- "Years of Working"
var_label(data$phys_activity) <- "Physical Activity Score"
var_label(data$obesity) <- "Obesity Status"
var_label(data$depression) <- "Depression Status"

glimpse(data)

```

# **Part B: Exploratory Data Analysis**

## Summary Statistics

```{r}
library(summarytools)
print(dfSummary(data,  
                style        = "multiline",  
                varnumbers   = FALSE,
                valid.col    = FALSE
                ),
      method = "render")
```

**Interpretation:** The dataset comprises 200 observations with four variables, with no missing data across all variables. Depression status shows that the majority of respondents are not depressed (81.5%), while 18.5% are depressed. The mean duration of working years is 21.2 years (SD 11.8), with a median of 22 years and a wide range from 0 to 39 years, indicating substantial variability in work experience. Physical activity has a mean score of 4.9 (SD 2.8), a median of 5, and ranges from 0 to 10, suggesting generally moderate activity levels. In terms of obesity status, 29.5% of participants are classified as obese, while 70.5% are not obese, indicating that nearly one-third of the sample has obesity.

## Visualizations

### Histograms

```{r}
#| fig-cap: "**Figure 1: Distribution of Continuous Variables**"

data |> 
  pivot_longer(c( years_working, phys_activity)) |> 
  ggplot(aes(value)) +
  geom_histogram(bins = 10, fill = "steelblue", color = "black") +
  facet_wrap(~name, scales = "free") +
  theme_minimal() +
  labs(
    x = "Value",
    y = "Frequency"
  ) +
  theme(
    plot.caption = element_text(hjust = 0.0, face = "bold", size = 10) 
  )


 
```

**Interpretation:** The Figure 1 illustrates the distribution of two continuous variables within a dataset. The phys_activity histogram shows a distribution centered around a score of approximately 4 to 5, indicating that the majority of participants report a moderate level of physical activity, with fewer individuals at the extreme low or high ends of the scale. Conversely, the years_working histogram displays a broader distribution across a 40-year span; the frequency generally increases with tenure, peaking significantly between 30 and 40 years. This suggests that the sampled population is primarily composed of individuals with extensive professional experience.

### Box Plots of Continuous Variables by Categorical Variables

```{r}
#| fig-cap: "**Figure 2: Box Plots of Continuous Variables by Obesity Status**"

data %>%
  pivot_longer(
    cols = where(is.numeric),
    names_to = "variable",
    values_to = "value"
  ) %>%
  ggplot(aes(obesity, value, fill = obesity)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ variable, scales = "free_y") +
  scale_fill_manual(values = c("not obese" = "#2E86AB", "obese" = "#F6C85F")) +  
  theme_minimal() +
  labs(
    x = "Obesity Status",
    y = "Value"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.caption = element_text(hjust = 0.0, face = "bold", size = 10))
```

**Interpretation:** The box plots in Figure 2 compare physical activity and years working across obesity status, showing that physical activity levels are remarkably similar between the two groups, with both sharing a median value of 5.0 and similar interquartile ranges. In contrast, there is a visible difference in years of working: the obese group has a higher median number of years working (approximately 24 years) compared to the not obese group (approximately 21 years).

```{r}
#| fig-cap: "**Figure 3: Box Plots of Continuous Variables by Depression Status**"


data %>%
  pivot_longer(
    cols = where(is.numeric),
    names_to = "variable",
    values_to = "value"
  ) %>%
  ggplot(aes(depression, value, fill = depression)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ variable, scales = "free_y") +
  scale_fill_manual(values = c("not depressed" = "blue", "depressed" = "red")) +  
  theme_minimal() +
  labs(
    x = "Depression Status",
    y = "Value"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.caption = element_text(hjust = 0.0, face = "bold", size = 10))
```

**Interpretation:** Figure 3 compares physical activity and years of working by depression status, revealing that while physical activity is only slightly lower in the depressed group (median $\approx 4.5$) compared to the not depressed group (median $= 5.0$), the difference in years working is substantial. The depressed group has a significantly higher median of approximately 32 years of work experience compared to 20 years for the not depressed group, although the depressed category also contains a few outliers with very low years of working.

### Scatter plots between continuous variables

```{r}
#| fig-cap: "**Figure 4 :Scatter plots showing relationships between  Work Experience, and Physical Activity.**"

plot_scatter <- function(x, y, title, xlab, ylab, col) {
  ggplot(data, aes({{ x }}, {{ y }})) +
    geom_point(alpha = 0.6, color = col) +
    geom_smooth(method = "lm", se = TRUE,
                color = col, fill = scales::alpha(col, 0.2)) +
    theme_minimal() +
    labs(title = title, x = xlab, y = ylab) +
    theme(
      plot.title = element_text(size = 10, face = "bold", hjust = 0.5),
      plot.margin = margin(10, 5, 10, 5)
    )
}

# 2. Assign plots to variables
plot_scatter(phys_activity, years_working,
                   "Years Working vs\nPhysical Activity", 
                   "Physical Activity", "Years Working", "#800080")


```

**Interpretation:** Figure 4 indicates a negligible correlation between the two variables, as evidenced by the nearly flat regression line centered around a value of approximately 21 years of working. While the individual data points are widely distributed across the entire range of both physical activity (0 to 10) and years of working (0 to 40), the shaded confidence interval suggests that an increase in physical activity does not correspond to a significant predictable change in years of working.

### Bar plots for categorical variables

```{r}
#| fig-cap: "**Figure 5 :Distribution of Obesity and Depression Status.**"

# Create Plot 1: Obesity
p1 <- ggplot(data, aes(x = obesity, fill = obesity)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Obesity Status",
       x = "Obesity Status",
       y = "Count") +
  scale_fill_brewer(palette = "Set3") +
  theme(legend.position = "none")

# Create Plot 2: Depression
p2 <- ggplot(data, aes(x = depression, fill = depression)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Depression Status",
       x = "Depression Status",
       y = "Count") +
  scale_fill_brewer(palette = "Set1") + # Different color for contrast
  theme(legend.position = "none")

# Combine plots side-by-side
p1 + p2
```

```{r}
#| fig-cap: "**Figure 6 :Distribution of Obesity Status by Depression Status.**"

# Obesity Status by Depression Status
ggplot(data, aes(x = obesity, fill = depression)) +
  geom_bar(position = "dodge") +
  theme_minimal() +
  labs(title = "Obesity Status by Depression Status",
       x = "Obesity Status",
       y = "Count",
       fill = "Depression") +
  scale_fill_brewer(palette = "Set2")

 
```

**Interpretation:** Figures 5 and 6 showed that the sample population is predominantly non-obese and not depressed.

### Correlation matrices for continuous variables

```{r}
#| fig-cap: "**Figure 7: Correlation Matrix of Years Working, and Physical Activity**"

continuous_vars <- data %>%
  dplyr::select(years_working, phys_activity)

# Compute correlation matrix
cor_matrix <- cor(continuous_vars, use = "complete.obs", method = "pearson")

 
# Plot correlation matrix
corrplot(
  cor_matrix,
  method = "color",
  type = "lower",
  tl.col = "black",
  tl.srt = 45,
  addCoef.col = "red",
  number.cex = 0.8,
  mar = c(0, 0, 2, 0)
)
```

**Interpretation:** Figure 7 shows correlation between the continuous variables. There is a very weak negative correlation ($r = -0.01$) between physical activity and years of working.

# **Part C: Regression Analysis**

## **Univariable Logistic regression models**

### Years working

```{r}
# 1. Fit the Logistic Regression model
yw <- glm(depression ~ years_working, 
                   data = data, 
                   family = binomial(link = "logit"))

# 2. Extract Tidy Results with Odds Ratios (OR)
yw_result <- tidy(yw, conf.int = TRUE, exponentiate = TRUE) |>
  mutate(p.value = format.pval(p.value, digits = 2, eps = 0.001))

# 3. Extract Model Fit (AIC and Pseudo-R2)
yw_fit <- glance(yw) |>
  dplyr::select(AIC, BIC, deviance, df.residual) |>
  mutate(pseudo_R2 = pR2(yw)["McFadden"]) 

kable(yw_result, digits = 3)
kable(yw_fit)

```

**Interpretation:** The logistic regression model indicates that years of working is a statistically significant predictor ($p < 0.001$), where each additional year of work experience increases the odds of the outcome by approximately 7.4% ($OR = 1.074$) with 95% CI (1.036, 1.118), explaining about 8.8% of the variance in the data (Pseudo $R^2 = 0.088$).

### Physical Activity

```{r}
 
# 1. Fit the Logistic Regression model
pa <- glm(depression ~ phys_activity, 
          data = data, 
          family = binomial(link = "logit"))

# 2. Tidy coefficients with Odds Ratios
pa_result <- tidy(pa, conf.int = TRUE, exponentiate = TRUE) |>
  mutate(p.value = format.pval(p.value, digits = 2, eps = 0.001))

# 3. Model fit with AIC and Pseudo-R2
pa_fit <- glance(pa) |>
  dplyr::select(AIC, BIC, deviance, df.residual) |>
  mutate(pseudo_R2 = pR2(pa)["McFadden"])

# Display results
kable(pa_result, digits = 3)
kable(pa_fit)
```

**Interpretation:** The logistic regression model indicates that physical activity is not a statistically significant predictor of the outcome ($p = 0.084$, $OR = 0.89$) with 95% CI (0.779, 1.014), and the overall model explains a negligible $1.6\%$ of the variance (Pseudo $R^2 = 0.016$).

### Obesity

```{r}
# 1. Fit the Logistic Regression model
ob <- glm(depression ~ obesity, 
          data = data, 
          family = binomial(link = "logit"))

# 2. Tidy coefficients with Odds Ratios
ob_result <- tidy(ob, conf.int = TRUE, exponentiate = TRUE) |>
  mutate(p.value = format.pval(p.value, digits = 2, eps = 0.001))

# 3. Model fit with AIC and Pseudo-R2
ob_fit <- glance(ob) |>
  dplyr::select(AIC, BIC, deviance, df.residual) |>
  mutate(pseudo_R2 = pR2(ob)["McFadden"])

# Display results
kable(ob_result, digits = 3)
kable(ob_fit)
```

**Interpretation:** The logistic regression analysis indicates that obesity status is not a statistically significant predictor of the outcome variable ($p = 0.106$), as the 95% CI ($0.867, 3.855$) encompasses the null value. The model demonstrates exceptionally low explanatory power, evidenced by a pseudo-$R^2$ of $0.013$.

### Summary of univariable analysis

```{r}

# 1. List of predictors
predictors <- c("years_working", "phys_activity", "obesity")

# 2. Fit univariable logistic regressions
uv_results <- lapply(predictors, function(var) {
  formula <- as.formula(paste("depression ~", var))
  model <- glm(formula, data = data, family = binomial)
  
  tidy_model <- broom::tidy(model) %>%
    mutate(
      OR = exp(estimate),
      lower = exp(estimate - 1.96 * std.error),
      upper = exp(estimate + 1.96 * std.error),
      variable = var,
      aic = AIC(model),
      pseudo_r2 = pR2(model)["McFadden"]
    )
  
  return(tidy_model)
}) %>% bind_rows()

# 3. Keep only the predictor rows (exclude intercept)
uv_results <- uv_results %>%
  filter(term != "(Intercept)") %>%
  dplyr::select(variable, estimate, OR, lower, upper, p.value, aic, pseudo_r2)

# 4. Format p-values and numbers
uv_results <- uv_results %>%
  mutate(
    estimate = round(estimate, 2),
    OR = round(OR, 2),
    lower = round(lower, 2),
    upper = round(upper, 2),
    aic = round(aic, 1),
    pseudo_r2 = round(pseudo_r2, 3),
    p.value = ifelse(p.value < 0.001, "<0.001", round(p.value, 3)),
    CI = paste0(lower, " - ", upper)
  )

```

```{r}
#| tbl-cap: "**Table 1: Univariable Logistic Regression Summary**"

# 5. Create gt table
gt_table <- uv_results %>%
  dplyr::select(variable, estimate, OR, CI, p.value, aic, pseudo_r2) %>%
  gt() %>%
  cols_label(
    variable = "Predictor",
    estimate = "Beta",
    OR = "OR",
    CI = "95% CI",
    p.value = "P-value",
    aic = "AIC",
    pseudo_r2 = "Pseudo R²"
  ) %>%
  fmt_number(columns = c("estimate", "OR"), decimals = 2) %>%  
  fmt_number(columns = c("aic", "pseudo_r2"), decimals = 3) %>%
  tab_options(
    table.font.names = "Arial",
    table.font.size = 14
    )

gt_table
```

**Summary:** The univariate analysis identifies "years_working" as the only statistically significant predictor, associated with an 8% increase in the odds of the outcome for each additional year ($OR = 1.08$; $95\% \text{ CI: } 1.03 - 1.12$; $p < 0.001$). In contrast, "phys_activity" ($OR = 0.89$; $95\% \text{ CI: } 0.78 - 1.02$) and "obesity" ($OR = 1.84$; $95\% \text{ CI: } 0.88 - 3.87$) do not reach statistical significance. Regarding multivariable inclusion, "obesity" and "phys_activity" meets common liberal screening criteria (e.g., $p < 0.25$).

```{r}
#| fig-cap: "**Figure 8 :Directed Acyclic Graph (DAG) Illustrating Causal Pathways Between Years of Working Duration, Physical Activity, Obesity, and Depression**"

library(dagitty)
library(ggdag)
library(ggplot2)

# Define DAG including the four variables (no interaction term in DAG)
dag_model <- dagify(
  dep ~ ob + pa + yw,
  ob ~ pa + yw,
  pa ~ yw,
  exposure = c("ob", "pa"),  
  outcome = "dep"
)

# Plot DAG
ggdag_status(dag_model, text_col = "white") +
  theme_dag() +
  scale_color_manual(values = c(
    "exposure" = "#0072B2",
    "outcome" = "#D55E00",
    "latent" = "grey"
  )) +
  theme(legend.position = "bottom")


```

**Legend :**

-   Physical activity = pa

-   Years working = yw

-   Obesity = ob

-   Depression =dep

**Interpretation:** The DAG identifies years of working and physical activity as critical causal antecedents that create "back-door paths" between obesity and depression, necessitating their inclusion in the multivariable model to ensure internal validity. Although phys_activity and obesity were not significant in univariate testing, their role as confounders within this structural framework requires adjustment to isolate the independent effect of obesity. By controlling for these variables, the model effectively blocks spurious associations stemming from occupational duration and lifestyle behaviors, transitioning the analysis from a simple p-value-driven selection to a robust, theory-based causal estimation.

## **Multivariable Logistic regression models**

### Model 1: Main effects only

```{r}
#| tbl-cap: "**Table 2: Multivariable Regression Model 1: Main Effects Only**"

# 1. Fit the Multivariable Logistic Regression model
m1 <- glm(depression ~ years_working + phys_activity + obesity, 
          data = data, 
          family = binomial(link = "logit"))

# 2. Extract results with Odds Ratios
tblm1 <- tidy(m1, conf.int = TRUE, exponentiate = TRUE) |>
  mutate(p.value = format.pval(p.value, digits = 2, eps = 0.001))

# 3. Calculate Model Fit Statistics
m1_aic <- glance(m1)$AIC
m1_pseudo_r2 <- pR2(m1)["McFadden"]

# 4. Display the main results table
kable(tblm1, digits = 3)

# Print Fit Stats
cat("Model Fit Statistics:\n",
    "AIC:", round(m1_aic, 2), "\n",
    "McFadden's Pseudo-R2:", round(m1_pseudo_r2, 4))


```

**Interpretation :** Model 1 indicates that years of working is the only statistically significant predictor of depression. Each additional year of working is associated with a 7.5% increase in the odds of depression (OR = 1.08; 95% CI: 1.04-1.12; *p* \< 0.001). Physical activity shows a protective direction but is not statistically significant (OR = 0.88; 95% CI: 0.76-1.01; *p* = 0.078), while obesity is associated with higher odds of depression, though with wide confidence intervals and no statistical significance (OR = 1.92; 95% CI: 0.87-4.23; *p* = 0.104), suggesting imprecision and possible limited power. The AIC of 177.09 reflects moderate model fit and McFadden’s pseudo-R² of 0.117 indicates that the model only explains about 11.7% of the variability in depression status.

### Model 2: Interaction between working years, physical activity and obesity

```{r}
#| tbl-cap: "**Table 3: Multivariable Regression Model 2: With Interaction Term**"

# 1. Fit the Logistic Regression model with Interaction
m2 <- glm(depression ~ years_working + phys_activity * obesity, 
          data = data, 
          family = binomial(link = "logit"))

# 2. Extract results with Odds Ratios
tblm2 <- tidy(m2, conf.int = TRUE, exponentiate = TRUE) |>
  mutate(p.value = format.pval(p.value, digits = 2, eps = 0.001))

# 3. Calculate Model Fit Statistics
m2_aic <- glance(m2)$AIC
m2_pseudo_r2 <- pR2(m2)["McFadden"]

# 4. Display results
kable(tblm2, digits = 3)

# Print Fit Stats
cat("Model Fit Statistics:\n",
    "AIC:", round(m2_aic, 2), "\n",
    "McFadden's Pseudo-R2:", round(m2_pseudo_r2, 4))


```

**Interpretation :** Model 2 shows that after including the interaction term, years of working remains significant (OR = 1.08; 95% CI: 1.04–1.12; *p* \< 0.001), obesity shows a strong effect on depression for individuals with low physical activity (OR = 12.20; 95% CI: 2.32–72.23; *p* = 0.004), and the interaction is significant (OR = 0.65; 95% CI: 0.44–0.91; *p* = 0.020), indicating that higher physical activity attenuates the effect of obesity. Model fit improves (AIC = 172.8) and explains more variability (McFadden’s pseudo-R² = 0.15), highlighting important effect modification.

### Compare Model 1 and Model 2

#### Likelihood Ratio Test

```{r}
#| tbl-cap: "**Table 4: Comparison of Models Using Likelihood Ratio Test**"

anova_tbl <- anova(m1, m2, test = "LRT")
kable(anova_tbl, digits = 3)

```

**Interpretation :** The likelihood ratio test comparing Model 1 and Model 2 shows a deviance reduction of 6.29 with 1 degree of freedom, which is statistically significant (p = 0.012). This indicates that including the interaction between physical activity and obesity significantly improves model fit compared with the main-effects-only model, supporting the use of Model 2 to capture this effect modification.

#### Using performance package

```{r}
#| tbl-cap: "**Table 5: Model Comparison of Model 1 & 2 Using Performance Metrics**"


library(performance)
compare_performance(m1, m2, rank = TRUE)
```

**Interpretation :** Model 2 (with interaction) shows better predictive performance than Model 1 across multiple indices: higher Tjur’s R² (0.166 vs 0.123), lower RMSE (0.351 vs 0.361), and lower log loss (0.407 vs 0.423), indicating improved discrimination and calibration. Percent correctly predicted (PCP) is slightly higher for Model 2 (74.8% vs 73.6%). Information-theoretic weights strongly favor Model 2 under AIC and AICc (≈0.89 vs 0.11), and it also has a higher overall performance score (77.8% vs 22.2%), though BIC weights are closer (0.621 vs 0.379), reflecting moderate penalization for complexity. Overall, these results suggest that Model 2 provides a superior fit and better captures the effect modification of physical activity on the obesity–depression association.

### Preliminary final model

```{r}
#| tbl-cap: "**Table 6: Preliminary Final Model Regression **"

# Variable labels
var_labels <- list(
  depression = "Depression Status",
  years_working = "Years Working",
  phys_activity = "Physical Activity Score",
  obesity = "Obesity Status"
)

# Function for pseudo R² (McFadden)
pseudo_r2 <- function(model) {
  1 - (model$deviance / model$null.deviance)
}

# Logistic regression table
tbl_model <- tbl_regression(
  m2,
  exponentiate = TRUE,       # show OR
  intercept = TRUE,
  conf.level = 0.95,
  label = var_labels,
  pvalue_fun = ~style_pvalue(.x, digits = 3, eps = 0.001),
  estimate_fun = ~style_number(.x, digits = 2)
) %>%
  bold_p() %>%
  bold_labels() %>% 
  modify_header(estimate ~ "**Adj. OR**") %>%
  add_glance_table(include = c(AIC)) %>%
  modify_caption("**Table 6: Preliminary Final Logistic Regression Model**") %>%
  modify_footnote(
    update = everything() ~ paste0("Pseudo R² (McFadden) = ", round(pseudo_r2(m2), 3))
  )

tbl_model


```

# **Part D: Model Checking**

## Check assumptions

### Generate predicted values and residuals

```{r}
data.fitted <- augment(m2)
```

### Assumption 1: Linearity of the logit for continuous predictors

To assess the assumption, we used a graphical approach where the predicted logit values from the logistic model were plotted against each continuous predictor, with smoothing curves overlaid to visually assess the linearity of the relationship (Hosmer & Lemeshow ,2013).

```{r}
#| fig-cap: "**Figure 9: Graphical Check of Linearity in the Logit**"

# Compute logit
data <- data %>%
  mutate(logit = log(predict(m2, type = "response") / 
                       (1 - predict(m2, type = "response"))))

# Reshape data for faceting
data_long <- data %>%
  dplyr::select(years_working, phys_activity, logit) %>%
  pivot_longer(cols = c(years_working, phys_activity),
               names_to = "variable",
               values_to = "value")

# Plot linearity in the logit
ggplot(data_long, aes(x = value, y = logit)) +
  geom_point(alpha = 0.5) +
  geom_smooth(aes(color = "LOESS"), method = "loess", se = TRUE) +
  geom_smooth(aes(color = "Linear"), method = "lm", se = FALSE) +
  facet_wrap(~variable, scales = "free_x",
             labeller = labeller(variable = c(
               years_working = "Years Working",
               phys_activity = "Physical Activity"
             ))) +
  scale_color_manual(name = "Trend Line",
                     values = c("LOESS" = "#1f77b4", "Linear" = "#ff7f0e")) +
  labs(y = "Logit of Depression", x = NULL,
       title = "Linearity in the Logit: Continuous Covariates") +
  theme_minimal(base_size = 14) +
  theme(strip.text = element_text(face = "bold"),
        legend.position = "top")


```

**Interpretation :** The Figure 9 demonstrates that both Physical Activity and Years Working fullfilled the assumptions for logistic regression, as the LOESS smoothed curves (blue) closely track the linear trend lines (orange) without significant deviation. Specifically, Physical Activity exhibits a consistent linear decrease in the log-odds of depression, while Years Working shows a strong, positive linear relationship with the outcome.

### Assumption 2: Independence of Residuals

Since the data were collected cross-sectionally with one observation per individual, the assumption of independent residuals in logistic regression is considered satisfied.

### Assumption 3: Absence of Multicollinearity

Multicollinearity was assessed using Variance Inflation Factors (VIF).

```{r}
vif(m2)
```

**Interpretation :** All predictors, including the interaction term, yielded VIF values below the conservative threshold of 5.0, indicating no significant multicollinearity was detected.

## Assess Goodness-of-fit

### Hosmer-Lemeshow test

```{r}

hoslem.test(
  x = m2$y,
  y = fitted(m2),
  g = 10
)
```

**Interpretation :** The model 2 yields X² = 12.30 with 8 degrees of freedom and a p-value = 0.138. Since the p-value is greater than 0.05, there is no evidence of poor fit, indicating that Model 2 adequately describes the observed data.

### Classification Table

Predict classes based on a 0.5 threshold and create confusion matrix to calculate: Accuracy, Sensitivity, Specificity

```{r}

# Get predicted probabilities
m.prob <- augment(m2, type.predict = "response") |> 
  mutate(pred.class = factor(ifelse(.fitted > 0.5, "depressed", "not depressed"),levels = c("not depressed", "depressed")))

confusionMatrix(m.prob$depression, m.prob$pred.class)

cm <- confusionMatrix(
  data = m.prob$pred.class,
  reference = m.prob$depression,
  positive = "depressed"
)


```

**Interpretation :** The model achieves 84% overall accuracy and correctly identifies most individuals who are not depressed (sensitivity 84.3%), with moderate ability to detect depressed cases (specificity 77.8%). The positive predictive value is high (98.8%) due to the majority class, while the negative predictive value is low (18.9%), reflecting difficulty predicting the minority “depressed” group. Kappa (0.25) indicates only fair agreement beyond chance, and balanced accuracy (81.0%) accounts for class imbalance. Overall, the model performs well for the majority class but has limited predictive power for depression cases, consistent with the low prevalence in the dataset.

### ROC Curve and AUC

```{r}
#| fig-cap: "**Figure 10: Receiver Operating Characteristic (ROC) Curve for Model 2**"

# Build ROC object
roc_obj <- roc(data$depression, m.prob$.fitted)

plot(roc_obj, 
     legacy.axes = TRUE, 
     print.auc = TRUE, 
     print.auc.cex = 1.2)

```

**Interpretation :** The model’s ROC AUC of 0.746 indicates acceptable discriminative ability, meaning it can reasonably distinguish between depressed and not depressed individuals. While not excellent, an AUC above 0.7 suggests the model performs better than chance and provides useful predictive information, particularly for identifying the majority class.

## Checking influentials

### Cook’s distance

Cook’s distance is used to detect influential observations that could disproportionately impact the model’s estimates. A commonly used threshold for identifying such points is 4 divided by the total number of observations **(4/n)**.

```{r}
infl <- influence.measures(m2)
infl.val <- data.frame(infl$infmat)

cutoff.cook.d <- 4 / nrow(data)

influential.obs <- infl.val |> 
  mutate(obs_id = row_number()) |> 
  filter(cook.d > cutoff.cook.d)

cat("Number of influential observations:", nrow(influential.obs), "\n")
cat("Cut-off value for Cook's Distance:", cutoff.cook.d, "\n")


if(nrow(influential.obs) > 0) {
  influential.obs |> 
    dplyr::select(obs_id, cook.d, hat) |> 
    arrange(desc(cook.d)) |> 
    head(15)
}

```

```{r}
#| fig-cap: "**Figure 11: Cook's Distance Plot for Identifying Influential Observations**" 

plot(m2, which = 4, id.n = 5)
abline(h = cutoff.cook.d, col = "red", lty = 2)
```

**Interpretation**: The Cook's Distance plot identifies several influential observations that exceed the calculated cut-off value of 0.02, indicating that these specific data points disproportionately affect the model's estimated coefficients. Specifically, observations 51, 78, 108, 151, and 92 are flagged, with observation 51 exerting the greatest influence.

```{r}
# Top 5 most influentials obs
data[c(51,78,108,151,92 ), ] 
```

These points should be reviewed for potential data entry errors or anomalies. If no issues are identified, it is advisable to refit the model excluding these observations to evaluate how much they affect the regression results.

#### Residuals vs Leverage plot

```{r}
#| fig-cap: "**Figure 12: Residuals vs Leverage Plot**"

plot(m2, which = 5)
```

**Interpretation**: The Residuals vs Leverage plot indicates an absence of highly influential outliers; although points 51, 108, and 78 are highlighted, they fall well within the Cook’s distance thresholds (below 0.5), suggesting they do not disproportionately bias the model’s coefficients

### Using DFBETAS

We use threshold of 2/sqrt(n) to identify influential observations for each predictor.

```{r}
# Compute DFBETAS and display as a datatable
dfb <- dfbetas(m2)
dfb_long <- dfb |> 
  as.data.frame() |> 
  mutate(id = row_number()) |> 
  pivot_longer(
    cols = -id,
    names_to = "term",
    values_to = "dfbeta"
  )

# Cutoff
dfb_threshold <- 2 / sqrt(nrow(data))

# Identify influential observations
influential_dfb <- dfb_long |> 
  filter(abs(dfbeta) > dfb_threshold) |>
  arrange(desc(abs(dfbeta)))

influential_dfb %>%
  datatable()


```

```{r}
#| fig-cap: "**Figure 13: DFBETAS for Each Observation**"

# Plot DFBETAS with colorblind-friendly palette

ggplot(dfb_long, aes(x = id, y = dfbeta, color = term)) +
  geom_point(alpha = 0.7, size = 2.5) +
  geom_hline(yintercept = c(dfb_threshold, -dfb_threshold), linetype = "dashed", color = "red") +
  labs(
    title = "DFBETAS for Each Observation",
    x = "Observation ID",
    y = "DFBETA",
    color = "Predictor Variable"
  ) +
  scale_color_viridis_d(option = "D") +  # colorblind-friendly discrete palette
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "right",
    legend.title = element_text(face = "bold"),
    legend.text = element_text(size = 12),
    plot.title = element_text(face = "bold", hjust = 0.5)
  )
```

**Interpretation**: Figure 13 reveals that almost all points fall within the standard threshold (indicated by the dashed red lines), meaning that no individual observations exerted undue influence on the model coefficients.

### Using Leverage Values and Standardized Residuals Cutoff

We will flag observations with standardized residuals above 2 or below -2, and those with leverage values exceeding the calculated threshold. The leverage cutoff is computed as 2 × (p + 2) / n, where p is the number of predictors and n is the total number of observations.

```{r}
# Compute leverage cutoff
leverage_cutoff <- 2 * (length(coef(m2)) + 2) / nrow(data)

# Add row ID
data.fitted <- data.fitted %>%
  mutate(id = row_number())

# Identify influential points
influential <- data.fitted %>%
  filter(abs(.std.resid) > 2 | .hat > leverage_cutoff) %>%
  mutate(status = "Influential")

# Non-influential points
non_influential <- data.fitted %>%
  filter(!(abs(.std.resid) > 2 | .hat > leverage_cutoff)) %>%
  mutate(status = "Normal")

# Combine
plot_data <- bind_rows(influential, non_influential)

# Display influential points in a datatable
influential %>% datatable()

```

```{r}
#| fig-cap: "**Figure 14: Standardized Residuals vs Leverage**"

# Plot standardized residuals vs leverage
ggplot(plot_data, aes(x = .hat, y = .std.resid, color = status)) +
  geom_point(alpha = 0.8, size = 2.5) +
  geom_hline(yintercept = c(-2, 2), linetype = "dashed", color = "red") +
  geom_vline(xintercept = leverage_cutoff, linetype = "dashed", color = "red") +
  labs(
    title = "Standardized Residuals vs Leverage",
    x = "Leverage (.hat)",
    y = "Standardized Residuals (.std.resid)",
    color = "Observation Status"
  ) +
  scale_color_viridis_d(option = "D", end = 0.8) +  
  theme_minimal(base_size = 14) +
  theme(
    legend.position = "right",
    legend.title = element_text(face = "bold"),
    plot.title = element_text(face = "bold", hjust = 0.5)
  )
```

**Interpretation**: The Figure 14 shows that most observations clustered as Normal (green) within acceptable limits. Although several points are flagged as Influential (purple) due to high residuals or leverage, they do not cross critical thresholds that would suggest a disproportionate bias on the estimated associations.

## Model Refinement

We will conduct a sensitivity analysis by removing 12 influential observations consistently identified across Cook’s distance, supported by the leverage values, standardized residuals, and DFBETAs diagnostics. These points exerted disproportionate influence on regression estimates. Their exclusion aimed to improve model performance, stability, and interpretability of the logistic regression results.

### Refitted Model Following Cook’s Distance Outlier Removal

```{r}
#| tbl-cap: "**Table 7 : Multivariable Regression Model 3: Refitted Model**"

n <- nrow(data.fitted)

# Threshold for Cook's distance
cooks_thresh <- 4 / n

# Filter out influential points based on Cook's distance
data.cleaned <- data.fitted %>%
  mutate(.cooksd = cooks.distance(glm(depression ~ years_working + phys_activity * obesity,
                                      data = data.fitted, family = binomial))) %>%
  filter(.cooksd < cooks_thresh)

# Refit logistic regression on cleaned data
m3 <- glm(depression ~ years_working + phys_activity * obesity,
                 data = data.cleaned,
                 family = binomial)

tidy(m3, exponential = TRUE, conf.int = TRUE) %>%
  mutate(p.value = format.pval(p.value, digits = 3, eps = 0.001))

```

```{r}
# Model fit statistics
glance(m3)
```

### Model Performance Before and After Removal of Influential Observations

```{r}
#| tbl-cap: "**Table 8 : Model Comparison of Model 2 and Model 3 Using Performance Metrics**"

compare_performance(m2, m3, rank = TRUE)
```

**Interpretation**: After removing influential observations based on Cook’s distance, model 3 shows improved predictive performance and better fit statistics.

### Coefficient Comparison: Pre- and Post-Cook's Model

```{r}
#| tbl-cap: "**Table 9 : Comparison of Coefficient Estimates With and Without Outliers**"

coef_comparison <- tidy(m2) %>%
  dplyr::select(term, estimate) %>%
  rename(estimate_prelim = estimate) %>%
  left_join(
    tidy(m3) %>%
      dplyr::select(term, estimate) %>%
      rename(estimate_refit = estimate),
    by = "term"
  ) %>%
  mutate(
    change_in_estimate = estimate_refit - estimate_prelim,
    percent_change = (change_in_estimate / estimate_prelim) * 100
  )
coef_comparison
```

**Interpretation**: After removing influential observations, the refitted model shows substantial changes in key estimates. The intercept decreased markedly (−3.38 to −6.11, \~81% change). The effect of years_working increased (\~98%), reinforcing its positive association with depression, while physical_activity remained weak with minimal practical effect despite a large relative percent change. Obesity remained strongly associated, and the interaction between physical activity and obesity became more pronounced (\~115% change), suggesting a stronger moderating effect after removing the influential observations. Overall, the refit model demonstrates improved stability and more reliable estimates.

### Model Diagnostics Comparison: Pre- and Post-Cook's Model

```{r}
# Set up 2 columns × 2 rows layout
par(mfrow = c(1, 2), cex = 1.0)

# Residuals vs Fitted
plot(m2, which = 1, main = "Preliminary Model")
plot(m3, which = 1, main = "Post-Cook's Model")

# Q-Q Plot
plot(m2, which = 2, main = "Preliminary Model")
plot(m3, which = 2, main = "Post-Cook's Model")

# Scale-Location
plot(m2, which = 3, main = "Preliminary Model")
plot(m3, which = 3, main = "Post-Cook's Model")

# Cook's Distance
plot(m2, which = 4, main = "Preliminary Model")
plot(m3, which = 4, main = "Post-Cook's Model")
```

-   **Residuals vs Fitted :** By removing high-influence points, the predicted values range expanded and Pearson residuals became more concentrated around zero. The flatter LOESS curve in the second plot indicates that the model's estimates are no longer skewed by extreme observations, resulting in more robust and valid adjusted odds ratios.

-   **Q-Q Residuals:** In the Preliminary Model, extreme outliers (observations 51, 108, and 78) exhibited high deviance residuals that pulled the Q-Q plot away from the theoretical line. Following the removal of these high-influence observations, the Post-Cook's Model demonstrates a tighter fit along the diagonal, though ID 145 remains a notable outlier.

-   **Scale-Location:** In the Preliminary Model, high-influence outliers (observations 51, 108, and 78) exhibited exceptionally high standardized residuals (above 2.0), which skewed the red LOESS trend line upward at lower predicted values. Following the removal of these points, the Post-Cook's Model displays a smoother, more consistent upward trend in the LOESS curve across a wider range of predicted values (extending down to -8).

-   **Influential Observations (Cook’s Distance):** In the Preliminary Model, Observation 51 exerted a disproportionate influence on the model coefficients, with a Cook's distance exceeding 0.20, followed by notable impacts from observations 78 and 108. By removing these influential outliers, the Post-Cook's Model achieved a more balanced distribution of influence across the remaining data points; while observation 83 now holds the highest relative influence, its Cook's distance is significantly lower (approximately 0.10) than the original peak.

### Goodness-of-Fit Assessment: Preliminary vs Post-Cook's Model

```{r}
#| tbl-cap: "**Table 10 : Comparison of Logistic Regression Models Before and After Outlier Removal**"

# --- Predicted probabilities for both models ---
pred_prob_m2 <- predict(m2, type = "response")
pred_prob_m3 <- predict(m3, type = "response")

# --- Hosmer-Lemeshow goodness-of-fit ---
hl_m2 <- hoslem.test(m2$y, pred_prob_m2, g = 10)
hl_m3 <- hoslem.test(m3$y, pred_prob_m3, g = 10)

# --- Classification tables ---
pred_class_m2 <- factor(ifelse(pred_prob_m2 > 0.5, "depressed", "not depressed"),
                        levels = c("not depressed", "depressed"))
pred_class_m3 <- factor(ifelse(pred_prob_m3 > 0.5, "depressed", "not depressed"),
                             levels = c("not depressed", "depressed"))

conf_m2 <- confusionMatrix(pred_class_m2, factor(data.fitted$depression, levels = c("not depressed","depressed")))
conf_m3 <- confusionMatrix(pred_class_m3, factor(data.cleaned$depression, levels = c("not depressed","depressed")))

# --- ROC and AUC ---
roc_m2 <- roc(data.fitted$depression, pred_prob_m2)
roc_m3 <- roc(data.cleaned$depression, pred_prob_m3)

# --- AIC ---
aic_m2 <- AIC(m2)
aic_m3 <- AIC(m3)

# --- McFadden's pseudo-R2 ---
mcfadden_m2 <- pR2(m2)["McFadden"]
mcfadden_m3 <- pR2(m3)["McFadden"]

# --- Summary table for comparison ---
model_comparison <- tibble(
  Model = c("Preliminary (m2)", "Post-Cook's (m3)"),
  HL_pvalue = c(hl_m2$p.value, hl_m3$p.value),
  Accuracy = c(conf_m2$overall["Accuracy"], conf_m3$overall["Accuracy"]),
  Sensitivity = c(conf_m2$byClass["Sensitivity"], conf_m3$byClass["Sensitivity"]),
  Specificity = c(conf_m2$byClass["Specificity"], conf_m3$byClass["Specificity"]),
  AUC = c(auc(roc_m2), auc(roc_m3)),
  AIC = c(aic_m2, aic_m3),
  Pseudo_R2 = c(mcfadden_m2, mcfadden_m3)
)

#Tabulate comparison

model_comparison %>%
  kable(
    caption = " Table 7 : Comparison of Logistic Regression Models Before and After Outlier Removal ",
    digits = 3,
    align = "c"
  ) %>%
  kable_styling(full_width = F, position = "center", bootstrap_options = c("striped","hover"))

```

**Interpretation**:

After removing influential observations, Model 3 shows markedly improved goodness-of-fit and predictive performance compared with Model 2.

The Hosmer–Lemeshow p-value increased from 0.138 to 0.617, indicating better calibration, while overall accuracy rose from 84.0% to 88.8% and specificity improved from 18.9% to 24.0%. Discriminative ability increased substantially (AUC 0.746 → 0.857), and model fit metrics also improved, with AIC dropping from 172.8 to 112.5 and McFadden’s pseudo-R² rising from 0.150 to 0.305.

Overall, removing influential points produced a more stable, better-fitting model with stronger predictive performance.

# **Part E: Results Presentation and Interpretation**

## Final Model

```{r}

# 1. Tidy glm coefficients with β and Wald z
coef_table <- tidy(m3) %>%
  mutate(
    beta = round(estimate, 2),
    wald = round(estimate / std.error, 3)
  ) %>%
  select(term, beta, wald)

# 2. Base gtsummary table with exponentiated OR
final_model <- tbl_regression(
  m3,
  exponentiate = TRUE,       # show Adj. OR
  intercept = TRUE,
  conf.level = 0.95,
  label = var_labels,        # must include all terms
  pvalue_fun = ~style_pvalue(.x, digits = 3, eps = 0.001),
  estimate_fun = ~style_number(.x, digits = 2)
) %>%
  # 3. Merge β and Wald z
  modify_table_body(
    ~ .x %>%
      left_join(coef_table, by = c("variable" = "term")) %>%
      relocate(beta, .before = estimate) %>%   # Beta before Adj. OR
      relocate(wald, .before = p.value)        # Wald z before p-value
  ) %>%
  modify_header(
    estimate ~ "**Adj. OR**",
    beta ~ "**β**",
    wald ~ "**Wald z**"
  ) %>%
  bold_p() %>%
  add_glance_table(include = c(AIC, nobs)) %>%
  modify_caption("**Table 11: Final Multivariable Logistic Regression Model for Depression**") %>%
  modify_footnote(
    update = everything() ~ paste0("Pseudo R² (McFadden) = ", round(pseudo_r2(m3), 3))
  ) %>%
  as_gt()

final_model
```

## Final Model Equation

```{r}
coef_tbl <- tidy(m3)

beta0 <- round(coef_tbl$estimate[1], 2)
beta1 <- round(coef_tbl$estimate[2], 2)
beta2 <- round(coef_tbl$estimate[3], 2)
beta3 <- round(coef_tbl$estimate[4], 2)
beta4 <- round(coef_tbl$estimate[5], 2)

cat(paste0(
  "logit(P(depression=1)) = ", beta0, 
  " + ", beta1, " * YearsWorking + ", 
  beta2, " * PhysActivity + ", 
  beta3, " * Obesity + ", 
  beta4, " * (PhysActivity * Obesity)"
))

```

$$
\text{logit}\big(P(\text{depression} = 1)\big) = -6.11 + 0.14 \times\text{YearsWorking} + 0.02 \times\text{PhysActivity} + 4.36 \times\text{Obesity} - 0.93 \times(\text{PhysActivity} \times \text{Obesity})
$$

$$
\text{Odds of Depression} = \exp\big(-6.11 + 0.14 \times \text{YearsWorking} + 0.02 \times \text{PhysActivity} + 4.36 \times \text{Obesity} - 0.93 \times (\text{PhysActivity} \times \text{Obesity})\big)
$$

## Interpretation

**1. Model Performance & Overall Fit**

-   The final post-Cook’s model (m3) shows strong overall performance. The Hosmer–Lemeshow test p-value = 0.617 indicates no evidence of poor fit. Overall accuracy is 88.8%, with high sensitivity (98.8%) for identifying non-depressed individuals and improved specificity (24.0%) for depressed cases. The AUC = 0.857 demonstrates good discriminative ability, while AIC = 112.49 and McFadden’s pseudo-R² = 0.305 indicate a well-fitting model explaining \~30.5% of the variability in depression status.

**2. Interpretation of Coefficients (Main Effects & Interactions)**

-   The **intercept** represents the baseline odds of depression for an individual who has worked 0 years, has a physical activity score of 0, and is not obese. Under these reference conditions, the odds of depression are effectively near zero, providing a meaningful baseline for interpreting the effects of other predictors.

-   **Years** **Working**: Holding physical activity and obesity status constant, each additional year of working increases the odds of depression by **16%** (OR = 1.16, 95% CI: 1.08-1.25; p \< 0.001). This indicates a steady cumulative increase in depression risk across the working lifespan.

-   **The Interaction Effect (Physical Activity × Obesity):** The interaction between physical activity and obesity is statistically significant (OR = 0.39, 95% CI: 0.17-0.72; p = 0.008), indicating that the effect of physical activity on depression differs by obesity status. Consequently, the main effects of physical activity and obesity must be interpreted conditionally rather than in isolation.

-   **Effect of Physical Activity (Stratified by Obesity Status):**

    -   **Non**-**obese** **individuals** (reference group): Physical activity has minimal effect on depression (OR = 1.02, 95% CI: 0.82-1.26; p = 0.862), suggesting small or negligible changes in odds per unit increase in activity.

    -   **Obese** **individuals**: he beneficial effect of physical activity is moderated by the interaction term. Net effect = 0.02 × 0.39 ≈ reduction in odds, indicating that among obese individuals, increased physical activity substantially reduces the odds of depression, highlighting its protective role in this group.

-   **Effect of Obesity (Conditional on Physical Activity):**

    -   At low physical activity, obesity dramatically increases depression risk (OR = 78.40, 95% CI: 6.27–1,579.69; p = 0.002).

    -   As physical activity increases, the odds of depression among obese individuals decrease due to the interaction, demonstrating that higher physical activity attenuates the obesity-associated risk, although obese individuals still have higher odds than non-obese counterparts at equivalent activity levels.

**3. Practical Implications**

-   From a public health perspective, these findings highlight that physical activity is a highly effective intervention to reduce depression risk among obese individuals, with a disproportionately stronger protective effect in this group.

-   Public health programs should prioritize promoting regular physical activity, particularly targeting obese populations, to mitigate mental health disparities.

-   Occupational health strategies could also integrate activity-based interventions for workers with longer tenure, given the cumulative risk associated with years of working.

-   These findings support tailored lifestyle interventions as a cost-effective approach to prevent depression, improve population well-being, and reduce the burden of obesity-related mental health outcomes.

## Interaction plot

```{r}
#| fig-cap: "**Figure 15: Predicted Probability of Depression by Physical Activity and Obesity Status**"

library(interactions)

# Interaction plot for logistic regression
interact_plot(
  m3,
  pred = phys_activity,
  modx = obesity,
  plot.points = FALSE,        
  interval = TRUE,            
  outcome.scale = "response", 
  colors = c("steelblue", "red"),
  x.label = "Physical Activity Score",
  y.label = "Predicted Probability of Depression",
  legend.main = "Obesity Status",
  modx.labels = c("Not Obese", "Obese")
)

```

**Interpretation**: The interaction plot demonstrates that Obesity Status significantly moderates the effect of Physical Activity on the Predicted Probability of Depression. For individuals who are "Not Obese," the risk of depression remains consistently low regardless of activity levels. However, for "Obese" individuals, there is a dramatic, sharp decline in the probability of depression as physical activity increases, falling from approximately 0.75 at zero activity to near-zero as scores reach 7.5. This suggests that physical activity provides a profound, disproportionate protective benefit specifically for those with obesity, effectively closing the depression risk gap at higher activity levels.

# **Prediction**

## Create new data for prediction

```{r}
new_data <- expand.grid(
  years_working = seq(0, 40, by = 10),
  phys_activity = seq(0, 10, by = 2),
  obesity = c("not obese", "obese")
)

new_data |> datatable()
```

## Generate predictions with confidence intervals using final model

```{r}
predicted <- augment(m3, newdata = new_data, interval = "confidence", level = 0.95)
predicted |> datatable()
```

## Prediction visualization

```{r}

# Get predictions with standard errors
pred <- predict(m3, newdata = new_data, type = "link", se.fit = TRUE)

# Build dataframe with CI on probability scale
predicted <- new_data %>%
  mutate(
    fit_link = pred$fit,
    se_link  = pred$se.fit,
    lower_link = fit_link - 1.96 * se_link,
    upper_link = fit_link + 1.96 * se_link,
    .fitted = plogis(fit_link),
    .lower  = plogis(lower_link),
    .upper  = plogis(upper_link)
  )


```

```{r}
#| fig-cap: "**Figure 16: Predicted Probability of Depression by Physical Activity and Obesity Status**"

# Plot predicted probabilities with custom colors
ggplot(predicted, aes(x = phys_activity, y = .fitted, color = obesity, fill = obesity)) +
  geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 0.2, color = NA) +
  geom_line(linewidth = 1) +
    facet_grid(~ years_working, labeller = label_both) + 
  scale_color_manual(values = c("obese" = "red", "not obese" = "steelblue")) +
  scale_fill_manual(values = c("obese" = "red", "not obese" = "steelblue")) +
  theme_minimal(base_size = 12) +
  labs(
    subtitle = "Stratified by Years of Working (Model Predictions with 95% CIs",
    y = "Predicted Probability of Depression",
    x = "Physical Activity Score (0–10)",
    color = "Obesity Status",
    fill = "Obesity Status"
  ) +
  theme(
    legend.position = "bottom",
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold")
  )

```

**Interpretation**: Figure 16 illustrates that the predicted probability of depression is significantly higher for obese individuals (red line) compared to non-obese individuals (blue line), particularly when physical activity scores are low. As the number of years working increases, the baseline risk of depression for inactive, obese individuals rises sharply, peaking at nearly 100% for those with 40 years of work experience; however, this risk drops dramatically as their physical activity improves. In contrast, those in the "not obese" category maintain a consistently low and stable probability of depression across all levels of physical activity and career lengths, suggesting that exercise serves as a vital protective factor specifically for the obese population in this model.

# **Conclusion**

The final logistic regression model demonstrates that years of working, obesity status, and the interaction between physical activity and obesity are key determinants of depression risk. While longer working tenure increases depression odds, physical activity provides a significant protective effect, particularly among obese individuals, attenuating their elevated risk. The model shows strong fit and predictive performance (AUC = 0.857, pseudo-R² = 0.305), supporting the robustness of these findings. From a public health perspective, interventions promoting physical activity (especially targeting obese populations) along with workplace wellness programs, can effectively reduce depression risk and improve mental well-being, highlighting the importance of tailored, lifestyle-based strategies in mental health prevention.

# **References**

1.  D. McFadden. Conditional logit analysis of qualitative choice behavior. In P. Zarembka, editor, *Frontiers in Econometrics*, chapter Four, pages 104–142. Academic Press, New York, 1974.

2.  Hosmer, D. W., Lemeshow, S. (2013). Applied logistic regression. John Wiley and Sons.

3.  Katz, M. (2011). Multivariable Analysis: A Practical Guide for Clinicians and Public Health Researchers (3rd ed.). Cambridge: Cambridge University Press. doi:10.1017/CBO9780511974175

4.  Kleinbaum, D. G. (2010). Logistic Regression A Self Learning Text. 2010. Springer.

5.  Musa, K. I., Arifin, W. N., and Hanis, T. M. (2024). Data Analysis in Medicine and Health using R. Boca Raton: CRC Press. 
